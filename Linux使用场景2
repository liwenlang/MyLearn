
【awk命令】
 
【实例 | 技巧】
last -n 5 | awk '{print $1 "\t" $3}'                    # 前5个登录账号，IP
free -m | grep "Mem" | awk '{print $2}'           # 显示内存大小
ifconfig eth0 | grep "inet addr:" | awk '{print $2}' | cut -c 6-     # 显示IP地址
awk -f script.awk $INPUT_FILES                         # 另一种调用脚本方式
awk '{v=FILENAME} !a[v]++1' *.log  >ALL.log   # 合并多为文件为一个
cat /etc/passwd | awk -F: '{print $1 "\t" $7}'      # 输出用户对应的shell
last | awk '{print $1 "\t lines:" NR "\t columns:" NF}'  # NR, NF运用
cat /etc/passwd | awk 'BEGIN {FS=":"} $3<10 {print $1 "\t" $3}' #BEGIN
cat /etc/passwd | awk '{FS=":"} $3<10 {print $1 "\t" $3}'  # 第一行默认空格
awk -F: '/root/{print $1 "\t" $7}' /etc/passwd    # 按关键字搜索//放置在{}前
awk '{max = $1 > $5 ? $1:$5 print max}' filename   # 三元表达式的运用
awk '$3 ~/^d/ {print "Matched, OK!"}' inputfile   # 模式匹配
awk '($1 > 10) && ($2 < 10) {print "OK"}' inputfile  # &&连接布尔表达式
awk '/^d/  || /on$/ {print "OK"}' inputfile  # ||连接正则表达式
cat /etc/passwd | awk '/^root/,/^admin/ {print $0}'  # root, admin之间的行
awk '{print FILENAME,$0}' file*.txt > file_all    # 合并每个文件前面加文件名
awk '{i=1;while (i<NF){print NF,$i;i++}}' /etc/passwd   # 通过while语句来实现循环
echo -e "one two three four" | awk '{print $(NF-1)}'  # 取倒数第二个字段
ps -ef | grep httpd | grep -v "grep" | awk '{print $2}' | xargs kill -9  # 杀掉所有httpd进程
awk '{print $1}' access.log | sort | uniq -c | sort -nr | head -10 # 统计访问最多的前十个 IP 地址
cat -n /etc/passwd | awk 'NR >= 10' | awk 'NR <= 20'  # 查看10行到20行
awk -F'[,\t|]' '{print}' file         # 多个分隔符Tab，逗号，|
Flag="Shell"; awk '{print '$Flag'}'     # 变量的使用
awk '/^(yes|no)/{print}' file   # 打印开头为yes或者no开头的行
echo | awk '{printf("hello word!n") > "datafile"}'   # awk允许这样输出文档
【归纳 | 总结】
【备注一】awk的三种调用方式:
方式一: 命令行方式:awk [-F 分隔符]  'commands'  input-file(s)
方式二: shell脚本方式: 首行添加#!/bin/awk
方式三: 将awk命令插入一个文件然后调用：awk -f awk_file input-file(s)
【备注二】关于awk命令的几点说明:
(01) awk有三个不同版本:awk、nawk和gawk，一般指gawk，是AWK的GNU版本
(02) awk取自Alfred Aho,Peter Weinberger和Brian Kernighan姓氏的首个字母
(03) awk相比于sed，更趋向于分成数个字段来处理，适合处理小型数据.
(04) {}中如有多个命令，以;来分隔
(05) 逻辑运算中，等号务必使用==
(06) awk中调用系统变量必须用单引号，如果是双引号，则表示字符串
(07) 格式化输出时，在printf的格式设置中，务必加上\n才能换行
(08) 与bash shell中的变量不同，在awk中变量可直接使用，不必加$符号 
(09) 相比print，printf格式化字符串完全是C语言风格，代码更加清晰，易懂
(10) awk把输入文件的数据读入内存， 然后操作该数据副本，awk不会修改输入数据内容
(11) awk总是输出到标准输出，如果想输出到文件中，请使用重定向符
(12) 相比于屏幕处理， 不会出现内存溢出或处理缓慢的情况，且可以格式化处理
(13) NF与$NF区别: 前者是字段个数，后者是最后一个字段
(14) && 和 ||可以连接两个/regexp/或者布尔表达式，构成混合表达式
【总结一】匹配操作符:
	匹配: value ~ /regrex/
	不匹配: value !~ /regrex/
【总结二】awk各项功能拆解:
''      引用代码块
BEGIN 初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符
//     匹配代码块，可以是字符串或正则表达式
{}     命令代码块，包含一条或多条命令
；    多条命令使用分号分隔
END  结尾代码块，每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息
【ln命令】
 
【实例 | 技巧】
ln /etc/passwd /tmp/passwd-hd    # 建立passwd文件的硬连接，注意不加-s建立硬连接
ln -is /bin /root/bin                # 为/bin目录建个软连接，即快捷方式，存在则提示
【归纳 | 总结】
【备注一】软链接和硬链接区别: 
软链接：(Symbolic Link跟Windows下的快捷方式完全一样，因此:)
	软链接以路径的形式存在。类似于Windows操作系统中的快捷方式
	软链接可以跨文件系统，硬链接不可以
	软链接可以对一个不存在的文件名进行链接
	软链接可以对目录进行链接
硬链接：(Hard Link:是在同一分区下建立的数据关联，因此:)
	硬链接以文件副本的形式存在。但不占用硬盘实际空间
	不允许给目录创建硬链接
	硬链接只有在同一个文件系统中才能创建，不能跨文件系统
【备注二】软链接和硬链接使用实例: 
 
【扩展 | 引申】
【引申一】Linux下文件的读取方式:
第一步: 先通过一层一层的目录获取文件相关的关联数据
第二步: 再到对应的inode获取文件属性，以及文件内容数据所在的块。
第三步: 最后到块区域获取文件的数据。
硬连接只是在某个目录下新增一个该文件的关联数据，比如:/root/crontab为一个硬连接文件，它连接到/etc/crontab文件,也就是说/root/crontab与/etc/crontab是同一个文件，只是有两个目录(/root与/etc)记录了crontab文件的关联数据。
/root/crontab  --> 某处(crontab的inode和块)
/etc/crontab    --> 某处(crontab的inode和块)
无论删掉/etc或/root下的crontab,都不会改变crontab的inode和块! 这样做的唯一好处就是:安全.




【chown命令】
 
【实例 | 技巧】
chown -v admin install.log            # 将该文件的拥有者更改为admin
chown :qq /home/qq                 # 将qq目录的组更改为qq组
chown -R www:www /home/www/*   # 第一个www表示拥有者，第二个表示群组
【chmod命令】
 
【实例 | 技巧】
chmod +x /script/*.sh           # 设置所有脚本具备可执行的权限
chmod a+x file                  # 将file文件设置为都可读的权限
chmod ug+w, o-w file1 file2     # 设置文件拥有者，群组可写权限，其他人不可写权限
chmod 771 file                  # 用数字的方式来设置权限
chmod ug=rwx, o=x file          # 和上面的效果一致
chmod -R a+r *                  # 当前目录下的所有子目录与文件可供任何人读取
chmod a-x file                   #  收回任何用户对file的执行权限
chmod 4777 file                 # 设置用户ID，给属主，组，其他用户分配读、写和执行权限
【归纳 | 总结】
【备注一】chmod的几点说明:
(1) 有只读权限的用户不能用cd进入该目录：还必须有执行权限才能进入
(2) 有执行权限的用户仅在知道文件名，并拥有读权利才能访问目录下的文件
(3) 必须有读和执行权限才可以ls列出目录清单，或使用cd命令进入目录
(4) 有目录的写权限，可以创建、删除或修改目录下的任何文件或子目录
(5) 除了以上基本的用户权限外，还有setuid、setgid和粘滞位等设置
【备注二】权限模式说明:
	u(user:文件拥有者) 
	g(group:文件归属组) 
	o(others:其他) 
	a(all: 所有都是) 
	s(special:特殊权限, 设置用户或组的ID号) 
	l(lock:文件加锁其他人无法访问) 
	t(粘着位,防止文件被非属主删除)
【备注三】chmod命令常用实例:
 
【chgrp命令】
 
【实例 | 技巧】
chgrp -v admin /var/log/messages     #  改变messages文件的群组，并显示执行过程
chgrp --reference=file1 file2           #  更改file2的群组和file1一样
chgrp -R 0 testDir        #  将testDir目录下的所有文件和目录更改为群ID为0的群组
chgrp --dereference mysql link_file    # 将目标文件而非连接文件组设置为mysql
【归纳 | 总结】
【备注一】关于chgrp命令的几点说明:
(1) chgrp命令要变更的组名必须存在于/etc/group
(2) 只有root账号才有执行该命令的权限，所以执行时，要用sudo命令

2	文档编辑
【grep命令】
 
【实例 | 技巧】
grep root /etc/passwd  # 查找含root账号的行
grep -r root /etc  # 递归查找/etc目录下，含root字符串的文件
ps -ef | grep -i httpd | grep -v -n "grep" # 查找httpd进程并输出符合条件行数
cat /OSM/conf/versions.conf | grep -A 4 "BIOS" # 输出匹配行及后四行
grep -n -v '^$' file       # 显示所有非空行，并标出编号
ls -lart | grep "^[^d]"  # 查询当前目录下不为目录的所有文件
echo "This is test line."  | grep -E -o "[a-z]+\."  # 匹配到line.
seq 10 | grep "5" -C 3  --color   # 5前后三行，并以颜色显示
grep -q "test" file  # 不输出任何信息，成功则返回0，一般用于条件测试
echo this is a text line | grep -e "is" -e "line" -o  # 匹配多个模式
grep "main()" . -r --include *.{php,html}  # 当前目录中.php和.html文件中递归搜索字符"main()"
grep "main()" . -r --exclude "README"  # 在搜索结果中排除所有README文件
grep "main()" . -r --exclude-from filelist  # 在搜索结果中排除filelist文件列表里的文件
cat /etc/passwd | grep -m 1 "root"       # 最大只匹配一次，找到为止
ps -ef | egrep "(sshd|httpd)"             # 查看进程中含sshd或者httpd的进程
【归纳 | 总结】
【备注一】grep，egrep:
(1) grep：在没有参数的情况下，只输出符合RE（Regular Expression）字符
(2) egrep：等同于grep -E，和grep最大的区别就是表现在转义符上比如grep做次数匹配时\{n,m\}egrep则不需要直接{n，m}。egrep方便，快捷
【备注二】grep常用匹配:
	grep ok file          # 匹配'book'、'okey'、'ok'等
	grep '\<ok' file       # 匹配'ok'和'okey'等价于$ grep -E '^ok'
	grep '\<ok\>' file     # 只匹配ok，等价于$ grep -w ok file
【总结一】常用的国际模式匹配:
[[:upper:]]    大写字母A-Z   例如: $ grep [[:upper:]] /etc/passwd
[[:lower:]]    小写字母a-z
[[:digit:]]    数字0-9
[[:alnum:]]    字母，数字0-9A-Za-z
[[:space:]]    空格或TAB
[[:alpha:]]    字母A-Za-z
【总结二】grep中常用正则表达式:
^         锚定行的开始 如：'^grep'匹配所有以grep开头的行
$          锚定行的结束 如：'grep$'匹配所有以grep结尾的行
\<        锚定单词的开始，如:'\<grep'匹配包含以grep开头的单词的行 
\>        锚定单词的结束，如'grep\>'匹配包含以grep结尾的单词的行
.          匹配任意一个字符； 如：'gr.p',可匹配grp, grep等.
*          匹配零个或多个先前字符; .*一起用代表任意字符, 
[]          匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep
[^]        匹配一个不在指定范围内的字符，如：'^[^d]匹配一个开头非d的行
\(..\)       标记匹配字符，如'\(love\)'，love被标记为1
x\{m\}     重复字符x，m次，如：'o\{5\}'匹配包含5个o的行。 
x\{m,\}    重复字符x,至少m次，如：'o\{5,\}'匹配至少有5个o的行。 
x\{m,n\}   重复字符x，至少m次，不多于n次，如：'o\{5,10\}'匹配5-10个o的行
\w        匹配文字和数字字符，也就是[A-Za-z0-9]
\b        单词锁定符，如: '\bgrep\b'只匹配grep
【tr命令】
 
【实例 | 技巧】
echo "hello world" | tr a-z A-Z             # 大小写转换，输出HELLO WORLD
tr -s "[a-z]" < input > output              # 删除input文件中重复的小写字符
tr -s "[\r]" "[\n]" < file                     # 删除Windows/DOS下的^M, 用换行替代
echo "Hello World" | tr -d "Helo"          # 删除指定字符H, e, l, o输出为Wrd
echo $PATH | tr ":" "\n"                   # 将$PATH的:变成回车
echo "Hello,2015" | tr -c "0-9" "*"         # 将所有非数字字符用*替代
echo "Year is 2015" | tr -cd [:digit:]        # 移调所有非数字字符
cat plan.txt | tr -s "\n"                    # 可删空行
【归纳 | 总结】
【备注一】关于tr命令的几点说明:
(1)	tr(translate)命令是sed命令的简化版，tr命令能实现的功能， sed都能实现
(2)	[a-zA-Z0-9]: a-zA-Z内的字符组成的字符串和0-9组成的数字串
(3)	[O*n]:       表示字符O重复出现指定次数n, 比如[O*2]匹配OO
【备注二】 tr命令很容易搞错的一个地方:
echo "backup abc file" | tr "abc" "xyz"   # 它并不是将abc替换成xyz，而是
a --> x      a用x来替换
b --> y      b用y来替换
c --> z      c用z来替换
【备注三】 tr命令使用实例:
 
【wc命令】
 
【实例 | 技巧】
wc -lwc file1 file2                   # 统计两个文件的行数，单词数，字符数;和省略lwc参数相当
ls -l | wc -l                               # 统计当前目录下的文件数，目录数
cat /OSM/conf/versions.conf | wc         # 统计该文件中有多少行，多少单词，多少字符
last | grep [a-zA-Z] | grep -v "wtmp" | wc -l # 统计最近一个月登陆用户数
cat /etc/passwd | wc -l                    # 统计系统有多少账号
find / -name "*.sh" | xargs cat | grep -v "^$" | wc -l   # 统计所有shell脚本行数，去空行
【expr命令】
 
【实例 | 技巧】
expr length "Hello World"     # 计算字符串长度
expr substr "Hello World!"     # 截取子字符串
expr match "hi,2015" hi.*      # 输出匹配到的个数
expr quote "str"              # 字符串重现
expr index "Hello World!" o   # 取第一个出现字符的索引
tag=0; tag=`expr $tag + 1 `   # 用于Shell循环中增量运算
expr 4 - 1                    # 整数求差+ - /同样运算
expr 8 /* 3                     # 整数求积, 注意要转义
expr 8 % 3                     # 取余运算
expr "hello" : ".*"               # 通过这种方式可计算字符串的长度
【归纳 | 总结】
【备注一】expr命令的几点说明:
(1) expr最大作用是四则运算和字符串操作，但必须是整数的四则运算
(2) expr只适合整数运算，涉及到浮点数的，可以用下面方式来处理：
var=2
var=`echo "scale=1;$var*2.0" | bc` # bc预设输出整数，用scale 指定小数点位数
echo $var
【总结一】expr,let,bc命令比较:
(1) 在shell 中$() 与 ``等效。执行中间包含的命令语句，返回执行结果
(2) 效率:let==(()) > expr > bc; let和(())运行是内建命令，使用相同的算法
(3) let和expr的运算是整数运算，不包括浮点预算
(4) expr和bc是外部程序，bc的体积几乎为expr的3倍，载入内存消耗的时间也大
(5) 从运算能力来说，bc排第一位
【扩展 | 引申】
【引申一】通过expr命令来判断变量是否为整数:
 
【引申二】通过expr命令来判断输入值:
 
【引申三】通过expr命令的模式匹配功能取文件名:
VAR=file.doc ;expr $VAR : "\(.*\).doc" 
# expr通过制定冒号选项计算字符串字符数，.*指任意字符重复多次; 输出:file
【引申四】通过expr命令来获取取连接文件:
lrwxrwxrwx 1 root root  18 2015-11-21 23:45 file1 -> /file2 
所以 expr "$ls"  :  '.*-> \(.*\)$' 
会返回 -> 后面的字符串,在这里也就是 /file2 
实际上就是找到一个软链接所链接到的文件   
【sort命令】
 
【实例 | 技巧】
sort /etc/passwd    # 按ASCII排序，首字符1..10，这往往不是我们想要的
sort -M -u file        # 按月份来排序并去重
sort -n file1 file2 -o sorted.file       # 自然数升序排序后输出
ls -lart | sort -k5 -nr                        # 获取目录下文件大小的顺序
ps aux | sort -k6 -nr | head -n 10   # 获取当前系统中运行最耗内存的10个进程
cat /etc/passwd | sort -t ':' -k 3      # 以冒号分隔，以第三列来排序
cat /etc/passwd | sort -t ':' -k3nr    # 倒序排列，默认是顺序排序
cat /etc/passwd | sort -t':' -k 6.2,6.4 -k 1r  #先第六域第2-4个字符正向排序，再第一个域反向排序
cat /etc/passwd |  sort -t':' -k 7 -u  # 对/etc/passwd的第七个域进行排序，然后去重
sort -t . -k 1,1n -k 2,2n -k 3,3n -k 4,4n /etc/hosts    # 基于ip地址对文件排序
history | sort -k4 | awk '{print $4}' | uniq -c | sort -k1nr | head -n5  # 获取最常用的5的命令
【归纳 | 总结】
【备注一】关于sort命令的几点说明:
(1) +1 -1  指定的栏位来排序，已属于旧格式，目前最常用的还是-k方式
(2) 要在 LC_ALL、LC_COLLATE 或 LANG 环境变量配置为 En_US 的情况下排序
(3) LANG=En_US; export LC_ALL=C
(4) 重定向问题，用sort file > file 达不到目的，要么-o参数；要么重定向另外一个文件
(5) 注意-k分隔字段 2与2,2区别sort -t "|" -k 2 text   
1|101|2  
1|10|2  
sort -t "|" -k 2,2 text   
1|10|2  
1|101|2
(6) 多条件排序;-k 2,2n –k 3,3nr；先按照第二列升序，再按照第三列降序
(7) sort -n -k 2.2,3.1 facebook  第二列第2字符到第三列第1字符，不包括第三字段
【uniq命令】
 
【实例 | 技巧】
cat file | sort | uniq -dc         # 显示重复行的重复次数
uniq -u filename               # 显示不重复的行
uniq -f3 /var/log/messages    # 跳过前三个字段, f可以和数字连在一起
uniq -f 2 -s 2 file             # 跳过前两个字段和后两个字符
【归纳 | 总结】
【备注一】关于uniq命令的几点说明:
(1) 需要注意的地方是uniq只对相连的行进行处理，所以一般情况下要先进行sort操作 
(2) uniq命令的常用三个参数-d,-u,-c
【nl命令】
 
【实例 | 技巧】
nl /etc/passwd                   # 列出passwd的内容
nl -b a /etc/passwd              # 列出passwd 的内容，空本行也加上行号
nl -b a -n rz /etc/passwd         # 让行号前面自动补上0,统一输出格式
nl -b a -n rz -w 3 /etc/passwd     # 让行号以三位宽度显示
【归纳 | 总结】
【备注一】关于nl命令的几点说明:
	nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数-w 3调整为3位
	nl命令在linux系统中用来计算文件中行号。nl可以将输出的文件内容自动的加上行号！
	nl不同于cat -n， nl可以将行号做比较多的显示设计，包括位数与是否自动补齐0等等的功能
【sed命令】
 
【实例 | 技巧】
【读取】：r命令
sed '/test/r file' example               # file里的内容被读进来，显示在与test匹配的行后面
【替换】：s命令 
sed 's/test/mytest/g' example          # 在整行范围内把test替换为mytest
sed -n 's/^test/mytest/p' example      # 只打印那些行开头的test被替换成mytest的行
sed 's/^Hi,/& Tom/' example           # 所有以Hi,开头的行都会被替换成Hi, Tom
【删除】：d命令
sed '2d' file          # 删除file文件的第二行
sed '2,$d' file        # 删除file文件从第二行到末尾的所有行
sed '$d' file         # 删除file文件的最后一行
sed '/test/d' file     # 删除file文件包含“test”的行
【范围】：逗号
sed -n '/test/,/check/p' example   # 打印test和check之间的行
sed -n '5,/^test/p' example       # 打印从第五行开始到第一个包含以test开始的行之间的所有行
【编辑】：e命令
sed -e '1,5d' -e 's/test/check/' example   #第一条命令删除1至5行，第二条命令用check替换test。命令的执行顺序对结果有影响;如果两个命令都是替换命令，那么第一个替换命令将影响第二个替换命令的结果。
【写入】：w命令
sed -n '/test/w file' example   #在example中所有包含test的行都被写入file里。
【追加】：a命令
sed '/test/a\insert' sed.txt  #在匹配test行后面增加一行insert
【插入】：i命令
sed '/test/i\insert' sed.txt  #在匹配test行前面增加一行insert
【转换】：y命令
sed '1,10y/abcde/ABCDE/' example  
# 把1到10行内所有abcde转变为大写，注意，正则表达式元字符不能使用这个命令。
【下一个】：n命令
sed '/test/{ n; s/aa/bb/; }' example   #如果test被匹配，则移动到匹配行的下一行，替换这一行的aa，变为bb，并打印该行，然后继续。
【保持和获取】：h命令和G命令
sed -e '/test/h' -e '$G' example  # 任何包含test的行都被复制并追加到该文件的末尾
【保存和互换】：h命令和x命令
sed -e '/test/h' -e '/check/x' example    # 把包含test与check的行互换
【归纳 | 总结】
【备注一】关于sed命令的几点说明:
1. 不论什么字符，紧跟着s命令的都被认为是新的分隔符。
2. sed是基于行的，因此按顺序对每一行执行命令。sed将其结果写入标准输出，不修改任何输入文件
3. sed内部有两个空间，模式空间和保留空间。模式空间是对外用的，用于读取外部文件；保留空间是内部用的，用于暂存文本数据。常规处理只用到模式空间，sed将文件以行为单位读入模式空间内处理即可。
4. sed浏览输入文件时，缺省从第一行开始，两种方式定位：
	用行号，可以是一个简单数字，或是一个行号范围
	使用正则表达式
5. 尽可能使用字符类是很有利的，他们可以更好的适应非英语locale
6. 当匹配正则表达式时，须注意正则表达式是按照最长匹配，即贪婪匹配
【vi命令】
 
 
【归纳 | 总结】
 
 
 
【扩展 | 引申】
 


3	磁盘管理
【cd命令】
 
【实例 | 技巧】
cd ..                # 返回上一层工作目录
cd ~                # 返回当前用户的家目录, 等价于cd $HOME
cd                  # 也是返回当前用户的家目录，只是不带任何参数
cd /var/spool/mail   # 切换工作目录到...
cd ../../              # 进入上两层目录
cd ../cur_debug/     # 切换到同级目录
cd ~root            # 切换到root账号的家目录
cd -                 # 切换到前一次工作目录
【归纳 | 总结】
【备注一】关于cd命令的几点说明:
(1) chang directory，cd 切换工作目录, 是Linux中最基本的命令
(2) cd tmp\ dir       # 进入带空格的目录，用反斜杠来转义
(3) cd /etc/init.?     # 如果不知道具体名，又不想用TAB的话
(4) cd /etc/init.*     # 用*其实效果和用?相似
【df命令】
 
【实例 | 技巧】
df -h              # 以可读的方式来显示文件系统的磁盘使用情况
df --total -ah      # 显示最后输出各列的合计,-a会显示虚拟文件系统，其大小为0
df -t ext3 -t ext4   # 显示指定类型的磁盘的使用情况
df -Th -x tmpfs     # 列出文件系统的类型，并排除tmpfs
【归纳 | 总结】
【备注一】虚拟文件系统几点说明:
(1) 虚拟文件系统是指没有相对应的物理设备的假文件系统
(2) 用-a参数可以显示虚拟文件系统,大小为0，加载于内存中
(3) 常用的虚拟文件系统有: cgroup,udev,proc,sys,tmpfs,devpts
(4) 优点:因加载于硬盘中，访问速度快。 缺点:数据容易丢失
【备注二】df命令查看信息解析:
 
	第1列是代表文件系统对应的设备文件的路径名,一般是硬盘上的分区
	第2列给出分区包含空间大小
	第3列表示已用的数据块数目
	第4列表示可用的数据块数目
	第5列表示使用空间的百分比
	第6列表示文件系统的挂载点
第3，4列块数之和不等于第2列中的块数。这是因为缺省的每个分区都留了少量空间供系统管理员使用。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单中Use% 列表示普通用户空间使用的百分比，即使这一数字达到100％，分区仍然留有系统管理员使用的空间。
【总结一】du与df命令的区别:
(1) du(disk usage):用户级命令;通过搜索文件来计算每个文件的大小然后累加，du能看到的文件只是一些当前存在的，没有被删除的。大小就是当前存在的所有文件大小的累加
(2) df(disk free):系统级命令;通过文件系统来快速获取空间大小的信息，当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小，他比du强的地方就是能够看到已经删除的文件，而且计算大小的时候，把这一部分的空间也加上了，更精确了。inode节点，磁盘分布图，间接块，超级块等，这些Meta Data对用户级是不可见，但对系统级用户是可见，必须考虑的。
(3) 当文件系统也确定删除了该文件后，这时候du与df就一致了
【总结二】使du与df一致的解决方案:
lsof | grep delete    # 找到相应的进程号
kill -9 <PID>        # 此时,使用df与du的命令,结果大致相同.
【du命令】
 
【实例 | 技巧】
du -sh  .                      # 以方便的方式显示当前目录的占用情况
du --max-depth=1 -h /etc      # 输出/etc目录及各个子目录所使用的空间
du -sh /tmp/* | sort -nr | head  # 前十占用空间最大的，便于清理
du --exclude="*test*"          # 列出当前目录中不包含test目录的大小
【归纳 | 总结】
【备注一】关于du与df命令的几点说明:
(1) du查看目录大小，统计文件大小相加，df查看磁盘使用情况，统计数据块使用情况
(2) du是面向文件的命令，只计算被文件占用的空间。不计算文件系统metadata 占用的空间
(3) df是基于文件系统总体来计算，通过文件系统中未分配空间来确定系统中已经分配空间的大小
(4) df获取硬盘占用了多少空间，还剩下多少空间，显示所有文件系统对i节点和磁盘块使用情况
【备注二】使用fuser -u命令真正清除已删除空间:
如果有一个进程在打开一个大文件的时候,这个大文件直接被rm或者mv掉，则du会更新统计数值，df不会更新统计数值,还是认为空间没有释放,直到这个打开大文件的进程被Kill掉。假如:我们定期删除/tmp下面的文件，但是没有杀掉其进程，所以空间一直没有释放。使用下面的命令杀掉进程之后，系统恢复。 fuser -u /tmp
【备注三】du命令实际运用示例:
查看/tmp目录下4个占用空间最大的文件或目录:
 
【tree命令】
 
【实例 | 技巧】
tree                    # 最常用，以树状图列出当前目录结构
tree -af                # 显示文件和目录的完整路径
tree -t                 # 以文件和目录的更改时间排序
tree --charset ASCII     # 防中文乱码的输出方式
tree -L 1               # 只列出第一级的目录和文件
tree -L 2 -d > tree.txt   # 列出两级目录和文件并重定向
【归纳 | 总结】
【总结一】以tree命令为例介绍Linux下包的编译步骤:
如果执行tree命令发现，命令没找到的话，说明该命令需要单独安装
$ tree 
-bash: tree: command not found
对于ubuntu系统: apt-get install tree; 对于linux系统: 可以用:wget命令
$ wget ftp://mama.indstate.edu/linux/tree/tree-1.5.3.tgz 
# 来下载最新的tree命令源代码压缩包。
$ ls -l tree-1.5.3.tgz 
-rw-r--r--    1 root     root        34494 12月  3 20:56 tree-1.5.3.tgz
$ tar zxf tree-1.5.3.tgz 
$ cd tree-1.5.3 
$ ls 
CHANGES  INSTALL  LICENSE  Makefile  man  README  strverscmp.c  tree.c
$ make 
gcc -ggdb -Wall -DLINUX -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64   
$ cp -af tree /usr/bin 这样tree命令就可以用了
使用示例:
 
【ls命令】
 
【实例 | 技巧】
ls /bin        # 列出bin目录下所有子目录
ll -h | less     # 分页方式详细列出了文件文件信息，ll相当于ls -l
ls -ltr *.sh     # 列出当前目录下所有的.sh文件，越新的排越后面
ls -lR  /bin   # 列出bin目录下所有子目录及文件的详细信息
ls -AF        # 列出当前目录下所有文件及目录，目录名称后加/，文件名后加*
ls -l * | grep "^-" | wc -l  # 计算当前目录下的文件数量
ls -lart                  # 按修改时间升序，并逆序排列
ls -lact                  # 按创建时间升序，并逆序排列
ls -lau                  # 按访问时间升序
$ find . name *.sh | xargs ls - lart  # 查到后按访问时间升序排列
$ ls --hide=*.py                 # 不列出.py结尾的文件，隐藏起来了
$ ls -Slr                         # 按照文件大小反向输出文件
$ ls -m                          # 所有文件名以逗号隔开，填满整行行宽，导成csv文件有用
$ ls -l /bin | grep "^d"           # 列出子目录的详细情况
$ ls -F /bin | grep /$              # 列出/bin目录下的子目录
$ find $PWD | xargs ls -ld         # 递归列出当前目录下的所有文件的绝对路径
$ find $PWD -maxdepth 1 | xargs ls -ld # 区别上例，对目录不递归
$ ls -tl --time-style=full-iso            # 指定文件时间输出格式
【归纳 | 总结】
【备注一】Linux下文件的一些文件颜色的含义:
(1). 绿色---->代表可执行文件
(2). 红色---->代表压缩文件
(3). 深蓝色---->代表目录
(4). 浅蓝色----->代表链接文件
(5). 灰色---->代表其它的一些文件
【备注二】Linux的文件类型:
(1)“-”代表普通文件
(2)“d”代表目录
(3)“l”代表连接文件
(4)“b”代表设备文件
(5)“s”代表套接字文件
 
【备注三】ls结合sed命令批量修改配置文件的目录的示例:
 
【pwd命令】
 
【实例 | 技巧】
pwd           # 不加参数，最常用用法，显示完整工作目录路径
pwd -P        # 显示真实目录路径，而非连接路径 
pwd -L        # 若有连接路径，则显示连接路径
echo "Current work dir: $PWD, the same as $(pwd), the previous Dir:$OLDPWD"
【归纳 | 总结】
【备注一】关于pwd命令的几点说明:
(1) mkdir来创建目录，cd进入指定的目录，pwd显示完整的目录
(2) 常用参数-P,-L 有时候需要注意是真实目录还是连接目录

【mount命令】
 
【实例 | 技巧】
mount -a                               # 挂载所有在/etc/fstab, /etc/mtab两个配置中的内容
mount -o remount,rw /dev/sda1         # 重新加载/dev/sda1为可读写权限
【光盘镜像文件的挂载】
mount -o loop -t iso9660 /home/test/mydisk.iso /mnt/vcdrom
【移动硬盘的挂载】
mount -t ntfs /dev/sdc1 /mnt/usbhd1
mount -t ntfs -o iocharset=cp936 /dev/sdc1 /mnt/usbhd1    # 文件名为汉字可以用这个命令
【U盘的挂载】
mount -t vfat /dev/sdd1 /mnt/usb
【Windows文件共享的挂载】
mount –o username=admin,password=123,iocharset=utf8//10.140.133.23/c$ /mnt/samba  
#admin和123 是10.140.133.23 Windows主机的用户名和密码，c$是这台计算机的一个磁盘共享名
【归纳 | 总结】
【备注一】关于mount命令的几点说明:
(1) 确保当前目录不在挂载点，否则mount或unmount都不会成功，会提示device is busy
(2) 想卸载某设备的语法是umount目录名，例如umount /mnt/cdrom等
(3) mount命令没有建立挂载点的功能，因此应该确保执行mount命令时，挂载点已经存在
(4) Windows网络共享的核心是SMB/CIFS，在Linux下要挂载Windows的磁盘共享，就必须安装和使用samba软件包
(5) 在linux客户端挂载NFS磁盘共享之前，必须先配置好NFS服务端
【扩展 | 引申】
【引申一】挂载设备需要的其他命令:
$ mkdir -p /mnt/vcdrom   # 建立目录作为挂载点
$ fdisk -l                  # 查看硬盘和硬盘的分区情况
$ more /proc/partitions    # 同上
$ cat /proc/filesystems     # 查看系统支持的文件类型
【引申二】制作光盘镜像文件:
将光盘放入光驱，执行下面其中之一的命令就可以:
	$ cp /dev/cdrom /home/root/disk.iso
	$ dd if=/dev/cdrom of=/home/root/disk.iso


4	磁盘维护
【badblocks命令】
 
【实例 | 技巧】
badblock -s -v /dev/sda1                       # 扫描硬盘分区/dev/sda1
badblocks -b 4096 -c 1 /dev/sda -o /tmp/result  # 检查保险箱盘
【归纳 | 总结】
【总结一】:Linux服务器如果让系统不使用损坏扇区或区块:
	步骤1: 使用fdisk命令识别硬盘信息:  fdisk -l
	步骤2: 扫描硬盘的损坏扇区或区块:  badblocks -v /dev/sda > /tmp/bad-blocks.txt
	步骤3: 提示操作系统不要使用损坏区块存储:  e2fsck -l /tmp/bad-blocks.txt  /dev/sda
PS: 在运行e2fsck命令前，请保证设备没有被挂载
【dd命令】
 
【实例 | 技巧】
dd if=/dev/sda of=/root/image count=1 bs=512     # 将sda盘的MBR信息备份
dd if=/dev/zero of=/dev/sda bs=100M count=100   # 对系统盘做毁灭性测试
dd if=/dev/sda | gzip> /tmp/back.gz                # 备份且压缩后放置到指定目录
gzip -dc /tmp/back.gz | dd of=/dev/sda             # 将压缩的备份文件恢复到指定盘
dd if=/dev/urandom of=/dev/sd-68a bs=1M count=10    # 利用随机数据下IO
time dd if=/dev/zero of=/tmp/file bs=1M count=100      # 用来测试纯写速度
time dd if=/tmp/file of=/dev/null bs=1M count=100      # 用来测试纯读速度
dd if=/dev/sda of=/dev/sda                             # 该命令用来修复长久未使用的硬盘
dd if=/dev/zero of=/tmp/test bs=100M count=1         # 创建一个100M的空文件用来测试
dd if=/etc/passwd of=/tmp/back                         # 用于拷贝文件
dd bs=512 count=100000 if=/dev/sda | gzip -9 > ghost.img.gz  # 系统克隆
【归纳 | 总结】
【备注一】dd几种输入设备:
(1)	/dev/null: 空设备，类似于Windows下的垃圾桶.of=/dev/null不产生IO，用来测试纯读速度
(2)	/dev/zero: 零设备, 提供无穷尽的0字符串，if=/dev/zero不产生IO，用来测试纯写速度
(3)	/dev/urandom:随机设备,if=/dev/urandom; 用来测试随机IO
【备注二】dd命令的几点说明:
(1) /dev/sda:          SCSI硬盘 
(2) /dev/hda:          IDE硬盘
(3) /dev/mapper/sda:  LVM分区
(4) 用dd制造文件的，文件大小不能超过内存大小，bs*count小于分区硬盘容量
【备注三】dd命令的实际运用中的示例:
 
【总结一】dd与cp区别:
	cp: copy，复制文件和目录,支持多个文件或目录拷贝。只拷贝文件本身的属性或特性
	dd: disk dump, 拷贝数据块；只把数据从一处拷贝到另一处，不支持多个文件或目录
【总结二】使用dd命令精确测试写速度和延迟:
$ dd if=/dev/zero of=/tmp/file1 bs=1G count=1 oflag=dsync #测试写速度
# oflag=dsync:用同步I/O,用该选项能够去除caching的影响，呈现精准的结果。
$ dd if=/dev/zero of=/tmp/file2 bs=512 count=1000 oflag=dsync  
# 测试服务器延迟
【总结三】使用dd命令清除缓存，精确测试读取速度:
$ flush
$ echo 3 | sudo tee /proc/sys/vm/drop_caches     # 清缓存
$ time dd if=/path/to/bigfile of=/dev/null bs=8k

【hdparm命令】
 
【实例 | 技巧】
hdparm /dev/sda                   # 显示硬盘的相关信息
hdparm -t /dev/sda                 # 评估硬盘的读取效率
hdparm -T /dev/sda                 # 测试硬盘缓存的读取速度
hdparm -m 4 /dev/sda              # 查询并设置硬盘多重扇区存取的扇区数
hdparm -tT --direct /dev/sda        # 直接测试硬盘的读性能
hdparm -cdt /dev/sda              # 查看DMA情况
hdparm -d 1 /dev/sda              # 开启DMA支持
【归纳 | 总结】
【备注一】dd与hdparm:
(1)	dd命令 ：它被用来在Linux和类Unix系统下对硬盘设备进行写性能的检测。
(2)	hdparm用来在基于Linux的系统上获取或设置硬盘参数，包括测试读性能以及缓存性能等
【备注二】检查和收集Linux硬件信息的几个命令:
	hwinfo 查询硬件信息
	lsppci  列出PCI总线的信息以及连接到PCI总线上的设备信息
	lsusb  列出USB总线信息
	lsblk  列出块设备的信息
	lsscsi 列出SCSI的设备信息 
【sync命令】
 
【mkfs命令】
 
【实例 | 技巧】
mkfs -t ext3 /dev/sda1       # 常用用法，为分区创建文件系统
mkfs -V -t ext3 -c /dev/sda1  # 并检查坏道，且详细显示
【归纳 | 总结】
【备注一】/sbin/mkfs.*文件说明:
$ ls /sbin/mkfs.*                            # 用来列出本地系统上创建文件系统的程序
执行mkfs其实是在调用:mkfs.ext3; mkfs.minix; mkfs.ext2 
$ mkfs.ext3 /dev/sda6                      # 把该设备格式化成ext3文件系统
【总结一】为新分区创建文件系统的完整步骤:
假如阵列上插入了新硬盘/dev/sd-70a,为该分区创建文件系统步骤如下:
$ mkdir -p /mnt/sd-70a                     # 创建挂载目录
$ chmod 777 /mnt/sd-70a                  # 赋予给定权限
$ mkfs -t ext3 /dev/sd-70a                  # 创建文件系统
$ mount /dev/sd-70a /mnt/sd-70a         # 挂载指定目录
PS: 执行该命令前，用fdisk -l来显示整个系统分区情况
 
【fsck命令】
 
【实例 | 技巧】
fsck              # 检查在/etc/filesystems文件中所有标记check=true的文件系统
fsck -p           # 为了检查一个特定的文件系统
fsck /dev/sda1    # 检查位于 /dev/sda1设备上的文件系统
fsck -t ext2 -a /dev/sda3  # 检查ext2文档系统/dev/sda3是否正常，如果有异常便自动修复
fsck -y /dev/sda2         # 检测系统，提示输入yes确认。一般用fdisk -l找到需要修复的设备后
【归纳 | 总结】
【备注一】关于mount命令的几点说明:
(1) 文件系统常见错误一般由下列情形导致:电源失败、硬件失败、或操作错误，例如没有正常关闭系统
(2) fsck只能运行于未mount的文件系统，不要用于已mount的文件系统
(3) 修复完成后，会出现提示“FILE SYSTEM WAS MODIFIED”；这时输入reboot命令重启系统即可
(4) 如果可能，先对故障区域做dd全镜像后再执行fsck命令,比如说: dd if=/dev/sda0 of=/dev/sdb0 
(5) 执行过程中，有大量inode错误、需要重建树、节点描述文件大小不正确等信息就要中断fsck
【备注二】mount命令的适用情形及常见症状:
[主要适用]
	文件系统：ext2 ext3 reiserfs xfs等
	范围：提示文件系统需要fsck时，未执行或fsck执行完成
[常见症状]	
	无法MOUNT分区
	大量文件、目录丢失，根目录下生成/LOST+FOUND文件夹，里面有大量#XXXXX类的文件和目录
	fsck很快报错完成
	fsck执行时，有大量提示，如修改节点、清0节点等操作
【fdisk命令】
 
【实例 | 技巧】
fdisk -l             # 显示当前全部分区
fdisk -lu            # 显示每块scsi硬盘的分区情况
fdisk -l  /dev/sda   # 观察实际硬盘使用情形
fdisk  /dev/sda     # 进入分割硬盘模式
【归纳 | 总结】
【备注一】为什么要有多个分区
(1) 防止数据丢失：如果系统只有一个分区，那么这个分区损坏，用户将会丢失所的有数据
(2) 增加磁盘空间使用效率：可以用不同的区块大小来格式化分区，如果有很多1K的文件，而硬盘分区区块大小为4K，那么每存储一个文件将会浪费3K空间。这时我们需要取这些文件大小的平均值进行区块大小的划分
(3) 数据激增到极限不会引起系统挂起：将用户数据和系统数据分开，可以避免用户数据填满整个硬盘，引起的系挂起
【总结一】添加分区的流程:
(1) fdisk  /dev/sda  
p        # 列出当前分区表
n        # 添加新分区
回车    # 选择开始的块地址,直接回车默认就可以了
+2G   # 输入要添加分区的大小+200M，+2G这样的都能识别
回车    # 确定
w        # 写入并退出
(2) partprobe                     #  更新当前分区表给内核，否则分区重启才能看到
(3) mkfs.ext3 /dev/sda4     # 格式化新建分区
(4) mount /dev/sda4 /mnt/sda4   # 挂载
PS: 
(1)如果自己操作错了，千万不要输入w,用q不保存退出!
(2)t参数可以对分区格式做转换，fd是raid类型,e8是做LVM时用到的pv类型
